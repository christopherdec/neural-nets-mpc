import data_utils as du
import training_utils as tu
import analysis_utils as au
import plot_utils as pu
import tensorflow as tf

# Decreases tensorflow's verbosity
import logging, os 
logging.disable(logging.WARNING) 
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

# Resets all state generated by tensorflow and set seed for reproducibility
tf.keras.backend.clear_session()
tf.random.set_seed(0)
tf.autograph.set_verbosity(0)

""" Carregamento de dados """

raw_data, variable_names = du.load_lote_3()

"""
import scipy.io
import pandas as pd
raw_data = scipy.io.loadmat('dados\\teste inputs\\sistema_teste.mat')['simout']
raw_data = pd.DataFrame(data=raw_data, columns=['u1', 'u2', 'u3', 'u4', 'y1'])
"""

# Os dicionários armazenam informações relevantes sobre os treinamentos
# Para explorá-los, utilizar o Variable explorer do Spyder ou o variableInspector do Jupyter Lab
dictionary = du.load_pickle("analysis\\dictionary.pickle")
# O dicionário de análise contém informações de interesse geradas a partir do dicionário de treinamentos
analysis_dict = du.load_pickle("analysis\\analysis_dict.pickle")


""" Configurações de execução """

# Se "run" for False, não entra no loop de treinamentos
exec_cfg = {
    "run" : True,
    "first y" : 1,
    "last y" : 1,
    "find inputs" : True,
    "find K" : True,
    "use all variables" : False,
    
    "input selection params" : {
        "max stages": 10,
        "trains per option": 1,
        "search patience": 2,
        "max epochs": 5000,
        "early stop patience": 3,
        "hidden layer nodes": 8,
        "horizon" : 200,
        "starting y order" : 2,
        "resampling factor": 1,
        "target loss": False, # 0.000001,
        "acceptable loss": False, # 0.000003,
        "min delta loss": False # 0.0000005
        #"test size": 0.3,
        },

    "K selection params" : {
        "K min": 6,
        "K max": 10,
        "trains per K": 3,
        "horizon" : 50,
        "search patience": 2,
        "max epochs": 5000,
        "target loss": False, # 0.0000008,
        "min delta loss": False, # 0.0000005,
        "early stop patience": 3,
        "resampling factor": 1
        #"train size": 0.65,
        #"validation size": 0.2,
        #"test size": 0.15,
        }
    }

""" Configurações de análise """

analysis_cfg = {
    "create analysis dict": True,
    "create model dict" : True,
    "single plots" : True,
    "multiplots" : False,
    "multiplot size" : 2,
    "save plots" : True   
    }


""" Início da execução """

if exec_cfg["run"]:
    
    for y in range(exec_cfg["first y"], exec_cfg["last y"] + 1):
        
        output = 'y' + str(y)

        print("Initializing training operations for output " + output)
    
        try:
            dependency = dictionary[output]["dependency mask"]
        except KeyError:
            dependency = None          
            try:
                dictionary[output]
            except KeyError:
                dictionary[output] = {}
                print("No dictionary entry for " + output + ", creating an empty object")
                
        if exec_cfg["use all variables"]:
            data = raw_data
        else:
            data = du.trim_data(raw_data, output, dependency)
        
        if exec_cfg["find inputs"]:
            regressors, input_selection_results = tu.input_selection(data, output, exec_cfg["input selection params"])
                
            dictionary[output]["input selection results"] = input_selection_results
            dictionary[output]["model"] = { "regressors" : regressors }
                
            du.save_pickle(dictionary, "analysis\\dictionary.pickle")
        else:
            try:
                regressors = dictionary[output]["model"]["regressors"]
            except KeyError: 
                print("No regressors found for " + output + ", please run input selection first")
             
        if exec_cfg["find K"]:
            K, weights, K_selection_results = tu.K_selection(data, regressors, output, exec_cfg["K selection params"])
            
            dictionary[output]["K selection results"] = K_selection_results
            dictionary[output]["model"]["K"] = K
            dictionary[output]["model"]["weights"] = weights
            
            du.save_pickle(dictionary, "analysis\\dictionary.pickle")
                              
        # deletes para deixar só os dicionários no variable explorer após último treinamento
        try: del data, regressors, dependency, output, y, K, K_selection_results, weights, input_selection_results
        except: pass
        

if analysis_cfg["create analysis dict"]:
    analysis_dict = au.run_analysis(dictionary)
    
if analysis_cfg["create model dict"]:
    model_dict = au.create_model_dict(dictionary)

if analysis_cfg["single plots"]:
    loss_info = pu.single_plots(dictionary, raw_data, save=analysis_cfg["save plots"])
    analysis_dict["plot evaluation"] = loss_info
    du.save_pickle(analysis_dict, "analysis\\analysis_dict.pickle")

if analysis_cfg["multiplots"]:
    pu.multiplots(dictionary, raw_data, size=analysis_cfg["multiplot size"], save=analysis_cfg["save plots"])
    
# deletes para deixar só os dicionários no variable explorer após último treinamento      
del exec_cfg, analysis_cfg, raw_data
    