

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>utils package &mdash; Neural Nets MPC 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="main file" href="main.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Neural Nets MPC
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="main.html">main file</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">utils package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.analysis_utils">analysis_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.custom_models">custom_models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.data_utils">data_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.plot_utils">plot_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.training_utils">training_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-utils.unused_functions">unused_functions</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Neural Nets MPC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>utils package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/utils.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="utils-package">
<h1>utils package<a class="headerlink" href="#utils-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-utils.analysis_utils">
<span id="analysis-utils"></span><h2>analysis_utils<a class="headerlink" href="#module-utils.analysis_utils" title="Permalink to this headline">¶</a></h2>
<p>Módulo para análise pós-criação dos modelos</p>
<dl class="py function">
<dt id="utils.analysis_utils.create_model_dict">
<code class="sig-name descname">create_model_dict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.create_model_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Cria o dicionário de modelos para exportação ao MPA, numa estrutura
específica que combinamos.</p>
<p>O .pickle salvo deve ser convertido em XML por um programa externo.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – training_dictionary, contendo os modelos criados</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dicionário contendo os parâmetros dos modelos criados</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.find_u_independent_models">
<code class="sig-name descname">find_u_independent_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.find_u_independent_models" title="Permalink to this definition">¶</a></dt>
<dd><p>Retorna uma lista dos modelos cujo regressors não teve nenhuma variável
de entrada (“u”) considerada no input selection.</p>
<p>Isso não é desejável, e pode indicar que o algoritmo está falhando em
identificar as relações entrada-saída para os modelos listados.</p>
<p>Idealmente esta lista estará vazia.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>lista com modelos “u” independentes</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.get_dependency_masks">
<code class="sig-name descname">get_dependency_masks</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.get_dependency_masks" title="Permalink to this definition">¶</a></dt>
<dd><p>Retorna um sub-dicionário com as máscaras de dependência
informadas para o input selection de cada modelo.</p>
<p>Geralmente não são informadas, e por padrão todas as variáveis de entrada
“u” e a própria saída “y” são utilizadas no input selection de cada
modelo. Neste caso, a string “default” é registrada como a máscara usada.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>sub-dicionário com as máscaras de dependência</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.get_execution_time_info">
<code class="sig-name descname">get_execution_time_info</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.get_execution_time_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Retorna informações sobre o tempo de execução para os input selection e
K selection, incluindo tempos máximo, mínimo e a média.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>sub-dicionário sobre os tempos de execução</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.get_selected_regressors">
<code class="sig-name descname">get_selected_regressors</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.get_selected_regressors" title="Permalink to this definition">¶</a></dt>
<dd><p>Pega os regressors escolhidos no input selection, para cada modelo
criado, e junta todos num sub-dicionário.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dicionário com todos regressors escolhidos</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.run_analysis">
<code class="sig-name descname">run_analysis</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.run_analysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Recebe o dicionário de treinamento, extrai e organiza informações úteis
deste em tópicos, retornando-as no dicionário de análise.</p>
<p>Para isso chama diversas funções simples do módulo de análise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dicionário de análise</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.analysis_utils.u_participation">
<code class="sig-name descname">u_participation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.analysis_utils.u_participation" title="Permalink to this definition">¶</a></dt>
<dd><p>Retorna um sub-dicionário que indica, para cada variável de entrada
“u”, uma lista indicando em quais modelos que esta tem participação.</p>
<p>Exemplo: “u1 = [y1, y5, y12]” indica que u1 é variável de entrada para
os modelos de y1, y5 e y12.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dictionary</strong> (<em>dict</em>) – dicionário de treinamento</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dicionário com a partipação das variáveis de entrada</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-utils.custom_models">
<span id="custom-models"></span><h2>custom_models<a class="headerlink" href="#module-utils.custom_models" title="Permalink to this headline">¶</a></h2>
<p>Módulo de modelos customizados</p>
<p>Contém a implementação em classe de modelos do tensorflow, dentre eles
o DLP, LSTM, GRU e Simple RNN. Os dois últimos foram movidos para
unused_functions.py, por não serem mais utilizados no código.</p>
<dl class="py class">
<dt id="utils.custom_models.LSTM">
<em class="property">class </em><code class="sig-name descname">LSTM</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'mse'</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.LSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação em classe da LSTM utilizando a Functional API</p>
<p>Para treinamento na configuração parallel (horizonte &gt; 1)</p>
<p>Baseado no tutorial de Timeseries do tensorflow</p>
<p>Pode ser utilizada apenas no input selection (alterando um parâmetro do
exec_cfg na main.py), porém o modelo final deve ser um DLP (sem
recursividade interna).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>horizon</strong> (<em>int</em>) – tamanho da janela de predição</p></li>
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
<li><p><strong>loss</strong> (<em>str</em><em>, </em><em>Loss</em><em>, </em><em>optional</em>) – função de custo. Defaults to ‘mse’.</p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>Optimizer</em><em>, </em><em>optional</em>) – Defaults to ‘adam’.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.custom_models.LSTM.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.LSTM.call" title="Permalink to this definition">¶</a></dt>
<dd><p>With the RNN’s state, and an initial prediction you can now
continue iterating the model feeding the predictions at each step
back as the input. The simplest approach to collecting the output
predictions is to use a python list, and tf.stack after the loop</p>
</dd></dl>

<dl class="py method">
<dt id="utils.custom_models.LSTM.warmup">
<code class="sig-name descname">warmup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.LSTM.warmup" title="Permalink to this definition">¶</a></dt>
<dd><p>The first method this model needs is a warmup method to initialize
its internal state based on the inputs. Once trained this state will
capture the relevant parts of the input history. This is equivalent to
the single-step LSTM model from earlier</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="utils.custom_models.ParallelModel">
<em class="property">class </em><code class="sig-name descname">ParallelModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'mse'</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.ParallelModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação em classe do DLP utilizando a Functional API</p>
<p>Para treinamento na configuração parallel (horizonte &gt; 1)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>horizon</strong> (<em>int</em>) – tamanho da janela de predição</p></li>
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
<li><p><strong>loss</strong> (<em>str</em><em>, </em><em>Loss</em><em>, </em><em>optional</em>) – função de custo. Defaults to ‘mse’.</p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>Optimizer</em><em>, </em><em>optional</em>) – Defaults to ‘adam’.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.custom_models.ParallelModel.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.ParallelModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Chamada para realizar as predições</p>
<p>Recebe o vetor y0, que informa o estado inicial de cada janela, com
dimensão (ordem de “y”, exemplos).</p>
<p>Também recebe as variáveis de entrada “u”, num vetor com dimensão
(entradas “u”, timestep, exemplos)</p>
<p>Um for percorre cada step do horizonte, e os valores calculados de ‘y’
são concatenados na entrada da rede com os valores dos ‘u’ para o
respectivo timestep</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>list</em>) – lista com o vetor y0 e vetor de inputs</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>predições</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="utils.custom_models.SSE">
<em class="property">class </em><code class="sig-name descname">SSE</code><a class="headerlink" href="#utils.custom_models.SSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.losses.Loss</span></code></p>
<p>Implementação da função custo Sum of Squared Errors</p>
<p>Resultados muito semelhantes à utilização do MSE</p>
<dl class="py method">
<dt id="utils.custom_models.SSE.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="n">y_pred</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.SSE.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Invokes the <cite>Loss</cite> instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> – Ground truth values, with the same shape as ‘y_pred’.</p></li>
<li><p><strong>y_pred</strong> – The predicted values.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="utils.custom_models.serial_parallel_model">
<code class="sig-name descname">serial_parallel_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'mse'</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.custom_models.serial_parallel_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementação do DLP utilizando a Sequential API</p>
<p>Exclusivo para horizonte = 1 (configuração de trainamento series-parallel)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
<li><p><strong>loss</strong> (<em>str</em><em>, </em><em>Loss</em><em>, </em><em>optional</em>) – função de custo. Defaults to ‘mse’.</p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>Optimizer</em><em>, </em><em>optional</em>) – Defaults to ‘adam’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>modelo compilado</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Sequential</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-utils.data_utils">
<span id="data-utils"></span><h2>data_utils<a class="headerlink" href="#module-utils.data_utils" title="Permalink to this headline">¶</a></h2>
<p>Módulo de carregamento e preparação de dados, também tem funções para
o carregamento e salvamento de objetos .pickle</p>
<dl class="py function">
<dt id="utils.data_utils.add_dependency">
<code class="sig-name descname">add_dependency</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">dependency</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.add_dependency" title="Permalink to this definition">¶</a></dt>
<dd><p>Função para informar a dependência de uma variável. Atualmente, deve ser
chamada no console. ‘dependency’ é uma lista com as variáveis que
influenciam na saida informada.</p>
<p>Carrega o training_dictionary e escreve na entrada “dependency mask” da
respectiva saída, salvando-o em seguida.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output</strong> (<em>str</em>) – saída a ser informada a dependência, exemplo: ‘y1’</p></li>
<li><p><strong>dependency</strong> (<em>list</em>) – variável influentes, exemplo: [‘u4’, ‘y1’, ‘y3’]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.build_sets">
<code class="sig-name descname">build_sets</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">regressors</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">return_Y_scaler</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">scaler</span><span class="o">=</span><span class="default_value">'MinMax'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.build_sets" title="Permalink to this definition">¶</a></dt>
<dd><p>A função build_sets extrai o máximo de exemplos possíveis de raw_data,
levando em conta as ordens das variáveis de entrada da rede, informada no
‘regressors’.</p>
<p>Exemplo: se output = ‘y1’, e regressors = [u1 = 1, u2 = 2, y1 = 3],</p>
<p>y1(k) = f(u1(k-1), u2(k-1), u2(k-2), y1(k-1), y1(k-2), y1(k-3))</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – conjunto de dados</p></li>
<li><p><strong>regressors</strong> (<em>pd.Series</em>) – variáveis de entrada e respectivas ordens</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>return_Y_scaler</strong> (<em>bool</em><em>, </em><em>optional</em>) – retorna scaler, só usado para plots.</p></li>
<li><p><strong>scaler</strong> (<em>str</em><em>, </em><em>optional</em>) – scaler, pode ser MinMax ou Standard.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DataFrame com os exemplos extraídos de raw_data
Y (pd.DataFrame): DataFrame de uma coluna com as labels Y
Y_scaler (optional): scaler do scikit-learn</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>X (pd.DataFrame)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.load_data">
<code class="sig-name descname">load_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">batch</span><span class="o">=</span><span class="default_value">'batch_1'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.load_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Função utilizada para carregar os dados de treinamento</p>
<p>Opções atuais: “batch_1”, “batch_2”, “batch_3”, “emso” ou “simulink”.
É necessário criar uma nova opção para importar novos dados. Deve retornar
um DataFrame com as colunas no formato “u1, u2, …, uNu, y1, y2, …,
yNy”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>str</em><em>, </em><em>optional</em>) – Defaults to “batch_1”.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>contém as amostras das variáveis do sistema
variable_names (dict): dicionário contendo o código de identificação
de cada variável, exemplo: u1 -&gt; XIA2017A
Ny (int): Número de saídas do sistema</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>raw_data (pd.DataFrame)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.load_pickle">
<code class="sig-name descname">load_pickle</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.load_pickle" title="Permalink to this definition">¶</a></dt>
<dd><p>Função utilizada para carregar arquivos .pickle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – caminho até o arquivo .pickle</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>objeto Python a ser retornado</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>stuff (object)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.recursive_sets">
<code class="sig-name descname">recursive_sets</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">y_order</span></em>, <em class="sig-param"><span class="n">shuffle</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.recursive_sets" title="Permalink to this definition">¶</a></dt>
<dd><p>Essa função prepara os dados para treinamento na configração Parallel,
cada exemplo não é mais uma única amostra, mas uma sequência de ‘horizon’
amostras. Para isso, X e Y são transformados em conjuntos tridimensionais.
E.g., se existem 10k dados e o horizonte de predição escolhido é 50,
teremos 200 exemplos de 50 janelas (amostras em sequência).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>pd.DataFrame</em>) – valores de entrada para cada exemplo</p></li>
<li><p><strong>Y</strong> (<em>pd.DataFrame</em>) – respectivo valor esperado na saída</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>horizon</strong> (<em>int</em>) – horizonte de predição/número de timesteps</p></li>
<li><p><strong>y_order</strong> (<em>int</em>) – ordem da variável de saída</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>optional</em>) – embaralha as janelas, deve melhorar o</p></li>
<li><p><strong>Defaults to False.</strong> (<em>desempenho.</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>array no formato (exemplo, timestep, variável)
Y (np.array): array no formato (exemplo, timestep, 1)
y0 (np.array): vetor que contém os estados iniciais dos regressores
da saída, para cada janela.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>X (np.array)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.save_pickle">
<code class="sig-name descname">save_pickle</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">stuff</span></em>, <em class="sig-param"><span class="n">path</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.save_pickle" title="Permalink to this definition">¶</a></dt>
<dd><p>Função utilizada para salvar arquivos .pickle</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stuff</strong> (<em>object</em>) – objeto Python a ser salvo</p></li>
<li><p><strong>path</strong> (<em>str</em>) – caminho até o arquivo .pickle a ser criado/sobreescrito</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.data_utils.shuffle_sets">
<code class="sig-name descname">shuffle_sets</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Y</span></em>, <em class="sig-param"><span class="n">return_array</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.shuffle_sets" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="utils.data_utils.trim_data">
<code class="sig-name descname">trim_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">raw_data</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">dependency</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.data_utils.trim_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Retorna o conjunto de dados apenas com as variáveis que serão
utilizadas na rede neural da saída atual. Se não se sabe quais são estas
variáveis, ‘dependency’ não é informada e assume-se que a saída é
influenciada apenas pelas variáveis manipuladas ‘u’ e por ela mesma.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>raw_data</strong> (<em>pd.DataFrame</em>) – conjunto de dados</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>dependency</strong> (<em>list</em><em>, </em><em>optional</em>) – variáveis que influenciam na saída atual.</p></li>
<li><p><strong>to None.</strong> (<em>Defaults</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>raw_data só com as colunas importantes</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-utils.plot_utils">
<span id="plot-utils"></span><h2>plot_utils<a class="headerlink" href="#module-utils.plot_utils" title="Permalink to this headline">¶</a></h2>
<p>Módulo de funções para plots</p>
<p>Utilizado após a criação dos modelos. Contém as funções
single_plots e multiplots.</p>
<dl class="py function">
<dt id="utils.plot_utils.multiplots">
<code class="sig-name descname">multiplots</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em>, <em class="sig-param"><span class="n">raw_data</span></em>, <em class="sig-param"><span class="n">size</span><span class="o">=</span><span class="default_value">[3, 3]</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">save_folder</span><span class="o">=</span><span class="default_value">'analysis'</span></em>, <em class="sig-param"><span class="n">horizon</span><span class="o">=</span><span class="default_value">'default'</span></em>, <em class="sig-param"><span class="n">baseline_in_title</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.plot_utils.multiplots" title="Permalink to this definition">¶</a></dt>
<dd><p>Esta função faz vários plots por figura, facilitando a visualização no
caso de muitas variáveis. Só plota modelos que foram criados, ou seja,
cujas informações estiverem no training_dictionary. O horizonte de predição
pode ser alterado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<em>dict</em>) – dicionário contendo info dos modelos criados</p></li>
<li><p><strong>raw_data</strong> (<em>pd.DataFrame</em>) – conjunto de dados não trimmados</p></li>
<li><p><strong>size</strong> (<em>list</em>) – lista contendo altura e largura dos multiplots</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>optional</em>) – salva as figuras. Defaults to False.</p></li>
<li><p><strong>save_folder</strong> (<em>str</em><em>, </em><em>optional</em>) – Defaults to “analysis”.</p></li>
<li><p><strong>horizon</strong> (<em>str</em><em>, </em><em>optional</em>) – “default” usa o mesmo horizonte utilziado</p></li>
<li><p><strong>K selection. Defaults to &quot;default&quot;.</strong> (<em>no</em>) – </p></li>
<li><p><strong>baseline_in_title</strong> (<em>bool</em><em>, </em><em>optional</em>) – calcula a baseline e appenda no</p></li>
<li><p><strong>Defaults to False.</strong> (<em>título.</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.plot_utils.single_plots">
<code class="sig-name descname">single_plots</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dictionary</span></em>, <em class="sig-param"><span class="n">raw_data</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_plots</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">save_folder</span><span class="o">=</span><span class="default_value">'analysis'</span></em>, <em class="sig-param"><span class="n">plot_baseline</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">horizon</span><span class="o">=</span><span class="default_value">'default'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.plot_utils.single_plots" title="Permalink to this definition">¶</a></dt>
<dd><p>Esta função faz um plot para cara modelo criado, a partir dos dados que
estão no dicionário de treinamento. O horizonte de predição utilizado nos
plots pode ser alterado. O desempenho é registrado num dicionário e a
baseline de ordem 0 (constante) também pode ser plotada.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<em>dict</em>) – dicionário contendo info dos modelos criados</p></li>
<li><p><strong>raw_data</strong> (<em>pd.DataFrame</em>) – conjunto de dados não trimmados</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>optional</em>) – salva as figuras. Defaults to False.</p></li>
<li><p><strong>show_plots</strong> (<em>bool</em><em>, </em><em>optional</em>) – mostra os plots. Defaults to True.</p></li>
<li><p><strong>save_folder</strong> (<em>str</em><em>, </em><em>optional</em>) – Defaults to “analysis”.</p></li>
<li><p><strong>plot_baseline</strong> (<em>bool</em><em>, </em><em>optional</em>) – Defaults to True.</p></li>
<li><p><strong>horizon</strong> (<em>str</em><em>, </em><em>optional</em>) – “default” usa o mesmo horizonte utilziado</p></li>
<li><p><strong>K selection. Defaults to &quot;default&quot;.</strong> (<em>no</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>dicionário contendo o SSE (sum of squared errors) de
cada modelo e sua baseline. é salvo depois no analysis_dict.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sse_info (dict)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-utils.training_utils">
<span id="training-utils"></span><h2>training_utils<a class="headerlink" href="#module-utils.training_utils" title="Permalink to this headline">¶</a></h2>
<p>Módulo de funções para criação e treinamento de modelos</p>
<p>Contém os algoritmos de input selection e K selection, para seleção da
estrutura dos modelos de rede neural.</p>
<dl class="py function">
<dt id="utils.training_utils.K_selection">
<code class="sig-name descname">K_selection</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">regressors</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.training_utils.K_selection" title="Permalink to this definition">¶</a></dt>
<dd><p>Seleciona o número de nodos (K) na hidden layer do DLP. Começa criando
uma rede com K_min, treina trains_per_K e guarda o melhor desempenho,
incrementa K e repete o processo, até atingir uma condição de parada.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – conjunto de dados</p></li>
<li><p><strong>regressors</strong> (<em>pd.Series</em>) – input variables escolhidas no input selection</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>params</strong> (<em>dict</em>) – parâmetros de execução</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>melhor valor determinado para K
best_weights (list): parâmetros treinados da rede com best_K nodes
search_results (dict): dicionário contendo informações do treinamento</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>best_K (int)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="utils.training_utils.create_models">
<code class="sig-name descname">create_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">exec_cfg</span></em>, <em class="sig-param"><span class="n">training_dictionary</span></em>, <em class="sig-param"><span class="n">raw_data</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.training_utils.create_models" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="utils.training_utils.input_selection_decremental">
<code class="sig-name descname">input_selection_decremental</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.training_utils.input_selection_decremental" title="Permalink to this definition">¶</a></dt>
<dd><p>Determina empiricamente o melhor conjunto de variáveis a ser utilizado
como entrada no modelo da saída atual. Esta versão é decremental, ou seja,
começa considerando starting_order para todas variáveis de entrada, e
decrementa uma das variáveis por estágio, escolhendo a que mais atrapalha
o desempenho, ficando somente as variáveis importantes no final, com a
ordem correta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – conjunto de dados retornado pela trim_data</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>params</strong> (<em>dict</em>) – diversos parâmetros de execução</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>contém as input variables e suas ordens
search_results (dict): dicionário contendo informações do treinamento,
como tempo de execução e as escolhas feitas em cada estágio.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>best_regressors (pd.Series)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-utils.unused_functions">
<span id="unused-functions"></span><h2>unused_functions<a class="headerlink" href="#module-utils.unused_functions" title="Permalink to this headline">¶</a></h2>
<p>Funções não utilizadas atualmente</p>
<p>Contém funções desenvolvidas que não são mais utilizadas no código,
foram trazidas para cá para melhorar a organização. Contém funções
que eram de training_utils.py e custom_models.py.</p>
<dl class="py class">
<dt id="utils.unused_functions.GRU">
<em class="property">class </em><code class="sig-name descname">GRU</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">K</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.GRU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação em classe da GRU utilizando a Functional API</p>
<p>Para treinamento na configuração parallel (horizonte &gt; 1)</p>
<p>Não utilizado e desatualizado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>horizon</strong> (<em>int</em>) – tamanho da janela de predição</p></li>
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.unused_functions.GRU.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.GRU.call" title="Permalink to this definition">¶</a></dt>
<dd><p>With the RNN’s state, and an initial prediction you can now
continue iterating the model feeding the predictions at each step
back as the input. The simplest approach to collecting the output
predictions is to use a python list, and tf.stack after the loop</p>
</dd></dl>

<dl class="py method">
<dt id="utils.unused_functions.GRU.warmup">
<code class="sig-name descname">warmup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.GRU.warmup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="utils.unused_functions.ParallelModel2">
<em class="property">class </em><code class="sig-name descname">ParallelModel2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">regressors</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'mse'</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">'adam'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.ParallelModel2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação em classe do DLP utilizando a Functional API</p>
<p>Implementado de uma maneira diferente, mas deu os mesmos resultados</p>
<p>Para treinamento na configuração parallel (horizonte &gt; 1)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>regressors</strong> (<em>pd.Series</em>) – input variables e respectiva ordem</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída para a qual a rede está sendo criada</p></li>
<li><p><strong>horizon</strong> (<em>int</em>) – tamanho da janela de predição</p></li>
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
<li><p><strong>loss</strong> (<em>str</em><em>, </em><em>Loss</em><em>, </em><em>optional</em>) – função de custo. Defaults to ‘mse’.</p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>Optimizer</em><em>, </em><em>optional</em>) – Defaults to ‘adam’.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.unused_functions.ParallelModel2.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.ParallelModel2.call" title="Permalink to this definition">¶</a></dt>
<dd><p>With the RNN’s state, and an initial prediction you can now
continue iterating the model feeding the predictions at each step
back as the input. The simplest approach to collecting the output
predictions is to use a python list, and tf.stack after the loop</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="utils.unused_functions.SerialParallelModel">
<em class="property">class </em><code class="sig-name descname">SerialParallelModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">loss</span><span class="o">=</span><span class="default_value">'mse'</span></em>, <em class="sig-param"><span class="n">optimizer</span><span class="o">=</span><span class="default_value">'adam'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.SerialParallelModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação do DLP utilizando a Functional API</p>
<p>Exclusivo para horizonte = 1 (configuração series-parallel)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
<li><p><strong>loss</strong> (<em>str</em><em>, </em><em>Loss</em><em>, </em><em>optional</em>) – função de custo. Defaults to ‘mse’.</p></li>
<li><p><strong>optimizer</strong> (<em>str</em><em>, </em><em>Optimizer</em><em>, </em><em>optional</em>) – Defaults to ‘adam’.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.unused_functions.SerialParallelModel.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.SerialParallelModel.call" title="Permalink to this definition">¶</a></dt>
<dd><p>With the RNN’s state, and an initial prediction you can now
continue iterating the model feeding the predictions at each step
back as the input. The simplest approach to collecting the output
predictions is to use a python list, and tf.stack after the loop</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="utils.unused_functions.SimpleRNN">
<em class="property">class </em><code class="sig-name descname">SimpleRNN</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">horizon</span></em>, <em class="sig-param"><span class="n">K</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.SimpleRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.engine.training.Model</span></code></p>
<p>Implementação em classe da RNN standard utilizando a Functional API</p>
<p>Para treinamento na configuração parallel (horizonte &gt; 1)</p>
<p>Não utilizado e desatualizado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>horizon</strong> (<em>int</em>) – tamanho da janela de predição</p></li>
<li><p><strong>K</strong> (<em>int</em>) – número de nodos na hidden layer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="utils.unused_functions.SimpleRNN.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.SimpleRNN.call" title="Permalink to this definition">¶</a></dt>
<dd><p>With the RNN’s state, and an initial prediction you can now
continue iterating the model feeding the predictions at each step
back as the input. The simplest approach to collecting the output
predictions is to use a python list, and tf.stack after the loop</p>
</dd></dl>

<dl class="py method">
<dt id="utils.unused_functions.SimpleRNN.warmup">
<code class="sig-name descname">warmup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.SimpleRNN.warmup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="utils.unused_functions.input_selection_incremental">
<code class="sig-name descname">input_selection_incremental</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#utils.unused_functions.input_selection_incremental" title="Permalink to this definition">¶</a></dt>
<dd><p>EM DESUSO! Essa é a versão incremental, originalmente utilizada, a
versão decremental teve melhores resultados.
Determina empiricamente o melhor conjunto de variáveis a ser utilizado
como entrada no modelo da saída atual. Esta versão é incremental, ou seja,
começa considerando ordem zero para todas variáveis de entrada (menos para
a saída, para manter recursividade), e selecionando a com melhor
desempenho em cada estágio.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pd.DataFrame</em>) – conjunto de dados retornado pela trim_data</p></li>
<li><p><strong>output</strong> (<em>str</em>) – saída atual</p></li>
<li><p><strong>params</strong> (<em>dict</em>) – diversos parâmetros de execução</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>contém as input variables e suas ordens
search_results (dict): dicionário contendo informações do treinamento,
como tempo de execução e as escolhas feitas em cada estágio.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>best_regressors (pd.Series)</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="main.html" class="btn btn-neutral float-left" title="main file" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Christopher de Carvalho.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>